{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5d2856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from transformers import GPT2Tokenizer\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca33656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "365ab701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RQ1: Step 1 - Setting up a prior belief based on targeted question\n",
    "\n",
    "#targeted questions\n",
    "question1 = \"Do you prefer direct next steps or detailed discussion first?\"\n",
    "question1_options=[\"1. direct steps\", \"2. detailed discussion\"]\n",
    "\n",
    "question2= \"Would you prefer a checklist or conversation?\"\n",
    "question2_options=[\"1. checklist\", \"2. conversation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ef79fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you prefer direct next steps or detailed discussion first?\n",
      "1. direct steps\n",
      "2. detailed discussion\n",
      "Would you prefer a checklist or conversation?\n",
      "1. checklist\n",
      "2. conversation\n",
      "['1. direct steps', '1. checklist']\n"
     ]
    }
   ],
   "source": [
    "#Function for asking question\n",
    "\n",
    "def ask_question(question, answer):\n",
    "    #question 1\n",
    "    print(question)\n",
    "    for i in range(len(answer)):\n",
    "        print(answer[i])\n",
    "    choice= input('Enter your preferred answer number') #change it to better UI based button later\n",
    "    return answer[int(choice)-1]\n",
    "\n",
    "\n",
    "choice_result = []\n",
    "\n",
    "choice_result.append(ask_question(question1, question1_options))\n",
    "choice_result.append(ask_question(question2, question2_options))\n",
    "\n",
    "print(choice_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "817a7e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preferred_conversation_style': 'action_based', 'ph1': None, 'ph2': None, 'peh1': None, 'peh2': None}\n"
     ]
    }
   ],
   "source": [
    "#creating user profile based on user's answer\n",
    "\n",
    "user_profile = {\"preferred_conversation_style\": None,\n",
    "                \"ph1\": None,\n",
    "                \"ph2\": None,\n",
    "                \"peh1\": None,\n",
    "                \"peh2\": None}\n",
    "\n",
    "#take 2 answers and based on that assign key-value pair for user profile--think\n",
    "\n",
    "\n",
    "if choice_result[0]==\"1. direct steps\" and choice_result[1] == \"1. checklist\":\n",
    "    user_profile[\"preferred_conversation_style\"] = \"action_based\"\n",
    "elif choice_result[0]==\"2. detailed discussion\" and choice_result[1] == \"2. conversation\":\n",
    "    user_profile[\"preferred_conversation_style\"] = \"relationship_based\"\n",
    "else:\n",
    "    user_profile[\"preferred_conversation_style\"] = \"mixed\"\n",
    "        \n",
    "print(user_profile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc7e4f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preferred_conversation_style': 'action_based', 'ph1': 0.9, 'ph2': 0.1, 'peh1': 0.4, 'peh2': 0.6}\n"
     ]
    }
   ],
   "source": [
    "#assign prior belief value - hardcoded, might change with an LLM prompt layer (step 1 completed)\n",
    "\n",
    "if user_profile[\"preferred_conversation_style\"] == \"action_based\":\n",
    "    user_profile[\"ph1\"] = .90\n",
    "    user_profile[\"ph2\"] = .10\n",
    "elif user_profile[\"preferred_conversation_style\"] == \"relationship_based\":\n",
    "    user_profile[\"ph1\"] = .10\n",
    "    user_profile[\"ph2\"] = .90\n",
    "else:\n",
    "    user_profile[\"ph1\"]=.60\n",
    "    user_profile[\"ph2\"]=.40\n",
    "    \n",
    "print(user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6888d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RQ1: Step 2 - Observing behavior with LLM prompt and treating each message like evidance P(E)\n",
    "\n",
    "user_input = \"Can you elaborate this topic?\"                          #input(\"Hi there! What you want to chat about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08962c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.set_default_device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]\n"
     ]
    }
   ],
   "source": [
    "#model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4491967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To analyze the provided user input, \"Can you elaborate this topic?\", we need to assess the user's intent, focusing on whether they are more action-based or relationship-based.\n",
      "\n",
      "An action-based user usually focuses on efficiency, outcomes, or getting tasks done quickly. They might use language that is direct and oriented towards completing a specific task or objective.\n",
      "\n",
      "A relationship-based user tends to focus on collaboration, understanding, and shared goals. They often value communication and mutual agreement.\n",
      "\n",
      "In this instance, the user's request for elaboration does not strongly indicate a focus on quick results or specific actions. Instead, it suggests a desire for more information and deeper understanding, which can align more with a collaborative and communicative approach.\n",
      "\n",
      "Given this analysis, an estimate for the probabilities could be:\n",
      "\n",
      "Output:\n",
      "peh1: 0.40\n",
      "peh2: 0.60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Create full prompt with few-shot examples\n",
    "full_prompt = f'''\n",
    "You are a conversation analyst. Estimate two probabilities:\n",
    "- peh1 = probability (0 to 1) that the user is Action-Based\n",
    "- peh2 = probability (0 to 1) that the user is Relationship-Based\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "Example 1:\n",
    "User: \"Tell me the fastest way to finish this project.\"\n",
    "peh1: 0.90\n",
    "peh2: 0.10\n",
    "\n",
    "Example 2:\n",
    "User: \"Before we start, can we discuss what's most important to focus on together?\"\n",
    "peh1: 0.20\n",
    "peh2: 0.80\n",
    "\n",
    "Example 3:\n",
    "User: \"I just want to get this over with quickly.\"\n",
    "peh1: 0.85\n",
    "peh2: 0.15\n",
    "\n",
    "Now, analyze the following user input:\n",
    "\n",
    "User: {user_input}\n",
    "\n",
    "Output:\n",
    "peh1:\n",
    "peh2:\n",
    "'''\n",
    "\n",
    "# Send the full prompt to OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",  # or \"gpt-3.5-turbo\", or \"gpt-4o-mini\"\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": full_prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response text\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bd04d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preferred_conversation_style': 'action_based', 'ph1': 0.9, 'ph2': 0.1, 'peh1': 0.4, 'peh2': 0.6}\n"
     ]
    }
   ],
   "source": [
    "for lines in response_text.splitlines():\n",
    "    if lines.strip().startswith(\"peh1\"):\n",
    "        user_profile[\"peh1\"] = float(lines.split(\":\")[1].strip())\n",
    "    elif lines.strip().startswith(\"peh2\"):\n",
    "        user_profile[\"peh2\"] = float(lines.split(\":\")[1].strip())\n",
    "        \n",
    "print(user_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77675bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3450134770889489 0.6549865229110511\n"
     ]
    }
   ],
   "source": [
    "#using bayesian theorem, calculating posterior \n",
    "\n",
    "numerator = user_profile[\"peh1\"] * user_profile[\"ph1\"]\n",
    "denominator = (user_profile[\"peh1\"] * user_profile[\"ph1\"]) + (user_profile[\"peh2\"] * user_profile[\"ph2\"])\n",
    "\n",
    "ph1e = numerator/denominator\n",
    "\n",
    "ph2e = 1 - ph1e\n",
    "\n",
    "print(ph1e, ph2e)\n",
    "\n",
    "# after first input\n",
    "user_profile[\"ph1\"] = ph1e\n",
    "user_profile[\"ph2\"] = ph2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef4edffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Notes on Arrays in Python\n",
      "\n",
      "#### Action-Based Style\n",
      "\n",
      "1. Create an array using Python's list feature.\n",
      "2. Access elements with index positions starting from 0.\n",
      "3. Example: `my_array = [1, 2, 3, 4, 5]`.\n",
      "4. Use `append()` to add an element: `my_array.append(6)`.\n",
      "5. Retrieve value: `value = my_array[2]`.\n",
      "6. Length of array: `len(my_array)`.\n",
      "7. Use loops to iterate over array elements.\n",
      "8. Remove element with `remove()`: `my_array.remove(3)`.\n",
      "9. Array slicing example: `sub_array = my_array[1:4]`.\n",
      "10. Sort array: `my_array.sort()`.\n",
      "\n",
      "#### Relationship-Based Style\n",
      "\n",
      "Arrays in Python are vital, offering a way to handle collections of data. Imagine a situation where you have a list of friends you want to manage smoothly. In Python, this is where arrays come in handy.\n",
      "\n",
      "Start by creating an array, much like writing down names on paper, using Python's intuitive list feature. For instance, you can jot down: `friends_list = [\"Alice\", \"Bob\", \"Charlie\"]`. Each item is at a specific index, emotions tagged to how you feel about each.\n",
      "\n",
      "Say you meet a new friend, David, and want to add him to your circle. The `append()` function is your ally: `friends_list.append(\"David\")`.\n",
      "\n",
      "Revisiting past memories is easy—just remember their index. When you want to know a friend at position 2, a simple `friend_at_2 = friends_list[2]` brings back those fond emotions associated with \"Charlie\".\n",
      "\n",
      "Removing a friend, unfortunately, happens too. Should a misunderstanding occur, use `remove()` to exclude them, as bittersweet as it sounds: `friends_list.remove(\"Bob\")`.\n",
      "\n",
      "Python arrays also let you reflect on a range of relationships. Simply slice through using `sub_list = friends_list[1:3]` to focus on specific connections.\n",
      "\n",
      "Finally, during those moments you wish to organize your thoughts and feelings, the `sort()` function arranges your friendships in an order that feels right: `friends_list.sort()`.\n",
      "\n",
      "Through arrays, Python lets you connect with your data as if it were your own social fabric—structured yet full of personal stories.\n"
     ]
    }
   ],
   "source": [
    "# Create full prompt with few-shot examples\n",
    "updated_prompt = f'''\n",
    "You're a Computer Science note maker. \n",
    "Generate notes for the user according to their preferred conversation style based on {ph1e} and {ph2e} score.\n",
    "\n",
    "ph1e means probability the user is action based given what they just said.\n",
    "ph2e means probability the user is relationship based given what they just said.\n",
    "\n",
    "if the user is action based, give output in the following format -\n",
    "1. direct and simple sentence\n",
    "2. short and concise sentence\n",
    "3. task focused and in bullet points\n",
    "\n",
    "if the user is relationship based, give output in the following format -\n",
    "1. direct and simple sentence\n",
    "2. storyline conversation\n",
    "3. focus on emotion and in paragraph style\n",
    "\n",
    "Now generate notes on Array using python coding language in 300 words. \n",
    "'''\n",
    "\n",
    "# Send the full prompt to OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # or \"gpt-3.5-turbo\", or \"gpt-4o-mini\"\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": updated_prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response text\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e102b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Arrays in Python\n",
      "\n",
      "### Introduction\n",
      "An array is a data structure that stores a collection of elements, usually of the same data type, in a contiguous block of memory. Arrays allow efficient access and manipulation of elements using indices.\n",
      "\n",
      "### Creating Arrays\n",
      "Python doesn't have a built-in array data type like some other languages (e.g., C, Java). However, you can use two main approaches for working with arrays:\n",
      "\n",
      "1. **Lists**: The most common Python data structure that can be used as an array. Lists are flexible but not as efficient in terms of speed and memory as true arrays.\n",
      "   ```python\n",
      "   # Creating a list\n",
      "   my_list = [1, 2, 3, 4, 5]\n",
      "   ```\n",
      "\n",
      "2. **Array Module**: Provides a true array data structure but is limited to basic types and operations.\n",
      "   ```python\n",
      "   import array\n",
      "   # Creating an array of integers\n",
      "   my_array = array.array('i', [1, 2, 3, 4, 5])\n",
      "   ```\n",
      "\n",
      "3. **NumPy Arrays**: NumPy is a powerful library for numerical computing in Python. NumPy arrays provide more functionality and efficiency compared to the array module's arrays.\n",
      "   ```python\n",
      "   import numpy as np\n",
      "   # Creating a NumPy array\n",
      "   np_array = np.array([1, 2, 3, 4, 5])\n",
      "   ```\n",
      "\n",
      "### Array Operations\n",
      "- **Accessing Elements**: Use indices to access elements.\n",
      "  ```python\n",
      "  element = my_list[2]  # Accesses the third element\n",
      "  ```\n",
      "  \n",
      "- **Modifying Elements**: Assign a new value to an index.\n",
      "  ```python\n",
      "  my_list[1] = 10  # Changes the second element to 10\n",
      "  ```\n",
      "\n",
      "- **Array Length**: Use `len()` to find the number of elements.\n",
      "  ```python\n",
      "  length = len(my_list)\n",
      "  ```\n",
      "\n",
      "- **Iterating Through Arrays**: Use loops to traverse arrays.\n",
      "  ```python\n",
      "  for item in my_list:\n",
      "      print(item)\n",
      "  ```\n",
      "\n",
      "### Advantages of Arrays\n",
      "- **Efficiency**: Arrays provide efficient access and modification of elements.\n",
      "- **Homogeneity**: Typically store elements of the same data type.\n",
      "- **Memory**: Contiguous memory allocation allows compact storage.\n",
      "\n",
      "### Disadvantages of Arrays\n",
      "- **Fixed Size**: Need to predefine size (not applicable to lists).\n",
      "- **Limited Methods**: Unlike lists, less flexibility with methods (especially true arrays).\n",
      "\n",
      "Arrays are an essential part of computer science, offering foundational support for various algorithms and data manipulation tasks in Python programming.\n"
     ]
    }
   ],
   "source": [
    "#without bayesian theorem approach \n",
    "without_theorem_prompt = f'''\n",
    "You're a Computer Science note maker. \n",
    "\n",
    "Now generate notes on Array using python coding language in 300 words. \n",
    "'''\n",
    "\n",
    "# Send the full prompt to OpenAI\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # or \"gpt-3.5-turbo\", or \"gpt-4o-mini\"\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": without_theorem_prompt},\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the response text\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc7af41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
